{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"S3eK0rrtbGBZFhsHBOEK\")\n",
    "project = rf.workspace(\"autoannotate-study\").project(\"berries-n34za\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf = Roboflow(api_key=\"S3eK0rrtbGBZFhsHBOEK\")\n",
    "project = rf.workspace(\"autoannotate-study\").project(\"fescue\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"S3eK0rrtbGBZFhsHBOEK\")\n",
    "project = rf.workspace(\"autoannotate-study\").project(\"red-leaf\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"S3eK0rrtbGBZFhsHBOEK\")\n",
    "project = rf.workspace(\"autoannotate-study\").project(\"buds-79ct6\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from ultralytics import SAM, YOLO\n",
    "\n",
    "def clean_labels(boxes, max_area):\n",
    "    clean_boxes = []\n",
    "    box_list = boxes.tolist()\n",
    "    for box in box_list:\n",
    "        if ((box[3]-box[1])*(box[2]-box[0]))<max_area:\n",
    "            clean_boxes.append(box)\n",
    "    if len(clean_boxes)<2:\n",
    "        return boxes\n",
    "    torch_tens = torch.FloatTensor(clean_boxes)\n",
    "    return torch_tens\n",
    "\n",
    "def auto_annotate(data, det_model=\"yolov8x.pt\", sam_model=\"sam_b.pt\", device=\"\", output_dir=None, prompt=\"Bud on shoot\", confidence=0.1, box_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Automatically annotates images using a YOLO object detection model and a SAM segmentation model.\n",
    "\n",
    "    Args:\n",
    "        data (str): Path to a folder containing images to be annotated.\n",
    "        det_model (str, optional): Pre-trained YOLO detection model. Defaults to 'yolov8x.pt'.\n",
    "        sam_model (str, optional): Pre-trained SAM segmentation model. Defaults to 'sam_b.pt'.\n",
    "        device (str, optional): Device to run the models on. Defaults to an empty string (CPU or GPU, if available).\n",
    "        output_dir (str | None | optional): Directory to save the annotated results.\n",
    "            Defaults to a 'labels' folder in the same directory as 'data'.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        from ultralytics.data.annotator import auto_annotate\n",
    "\n",
    "        auto_annotate(data='ultralytics/assets', det_model='yolov8n.pt', sam_model='mobile_sam.pt')\n",
    "        ```\n",
    "    \"\"\"\n",
    "\n",
    "    if 'world' in det_model:\n",
    "        det_model = YOLO(det_model)\n",
    "        det_model.set_classes([prompt])\n",
    "    else:\n",
    "        det_model = YOLO(det_model)\n",
    "    sam_model = SAM(sam_model)\n",
    "\n",
    "    data = Path(data)\n",
    "    if not output_dir:\n",
    "        output_dir = data.parent / f\"{data.stem}_auto_annotate_labels\"\n",
    "    Path(output_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "    #det_results = det_model(data, stream=True, device=device)\n",
    "    det_results = det_model.predict(data,conf=confidence,save=True, save_txt=True, verbose=False)\n",
    "\n",
    "    for result in det_results:\n",
    "        class_ids = result.boxes.cls.int().tolist()  # noqa\n",
    "        shape = result.orig_shape\n",
    "        boxes = result.boxes.xyxy\n",
    "        max_area = shape[0]*shape[1]*box_threshold\n",
    "        boxes = clean_labels(boxes, max_area)\n",
    "        if len(boxes):\n",
    "            sam_results = sam_model(result.orig_img, bboxes=boxes, verbose=False, save=True, device=device)\n",
    "            segments = sam_results[0].masks.xyn  # noqa\n",
    "\n",
    "            with open(f\"{Path(output_dir) / Path(result.path).stem}.txt\", \"w\") as f:\n",
    "                for i in range(len(segments)):\n",
    "                    s = segments[i]\n",
    "                    if len(s) == 0:\n",
    "                        continue\n",
    "                    segment = map(str, segments[i].reshape(-1).tolist())\n",
    "                    f.write(f\"{class_ids[i]} \" + \" \".join(segment) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_metrics(TP, FP, FN, TN):\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    mcc = ((TP * TN) - (FP * FN)) / np.sqrt((TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)) if np.sqrt((TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)) > 0 else 0\n",
    "    specificity = TN / (TN + FP) if TN + FP > 0 else 0\n",
    "    return precision, recall, f1, mcc, specificity\n",
    "\n",
    "def pixel_accuracy(predicted, ground_truth):\n",
    "    correct = np.sum(predicted == ground_truth)\n",
    "    total = predicted.shape[0] * predicted.shape[1]\n",
    "    return correct / total\n",
    "\n",
    "def read_and_draw_masks(file_path, image_dim=(1280, 720)):\n",
    "    boxes = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        masks = []\n",
    "        for line in file:\n",
    "            raw_mask = [float(x) for x in list(line.strip().split())]\n",
    "            points = []\n",
    "            for point in range(int((len(raw_mask)-1)/2)):\n",
    "                p1 = int(raw_mask[(2*point)+1]*image_dim[0])\n",
    "                p2 = int(raw_mask[(2*point)+2]*image_dim[1])\n",
    "                points.append([p1,p2])\n",
    "            masks.append(points)\n",
    "    canvas = np.zeros((image_dim[1], image_dim[0]), dtype=np.uint8)\n",
    "    for mask in masks:\n",
    "        cv2.fillPoly(canvas, np.array([mask], dtype=np.int32), 255)\n",
    "    #plt.imshow(canvas, cmap='gray')\n",
    "    #plt.axis('off')\n",
    "    #plt.show()\n",
    "\n",
    "    #image = Image.new('L', image_dim, 0)\n",
    "    #draw = ImageDraw.Draw(image)\n",
    "    #for box in boxes:\n",
    "        #draw.rectangle(box, fill=255)\n",
    "        #draw.rectangle([1,1,20,20], fill=255)\n",
    "    #image.save(\"test.jpg\")\n",
    "    return np.array(canvas, dtype=np.uint8)\n",
    "\n",
    "def calculate_pixel_metrics(mask1, mask2):\n",
    "    \"\"\"\n",
    "    Calculate IoU based on pixel values from two masks.\n",
    "    \"\"\"\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "def process_files_seg(predicted_mask_dir, ground_truth_mask_dir):\n",
    "    predicted_files = os.listdir(ground_truth_mask_dir)\n",
    "    metrics = {\n",
    "        'iou_scores': [],\n",
    "        'pixel_accuracies': [],\n",
    "        'precision_scores': [],\n",
    "        'recall_scores': [],\n",
    "        'f1_scores': [],\n",
    "        'mcc_scores': [],\n",
    "        'specificity_scores': []\n",
    "    }\n",
    "\n",
    "    for fname in predicted_files:\n",
    "        predicted_mask_path = os.path.join(predicted_mask_dir, fname)\n",
    "        ground_truth_mask_path = os.path.join(ground_truth_mask_dir, os.path.splitext(fname)[0] + '.txt')\n",
    "        if not os.path.exists(predicted_mask_path):\n",
    "            metrics['iou_scores'].append(0)\n",
    "            metrics['pixel_accuracies'].append(0)\n",
    "            metrics['precision_scores'].append(0)\n",
    "            metrics['recall_scores'].append(0)\n",
    "            metrics['f1_scores'].append(0)\n",
    "            metrics['mcc_scores'].append(0)\n",
    "            metrics['specificity_scores'].append(0)\n",
    "            continue\n",
    "\n",
    "        COMMON_HEIGHT, COMMON_WIDTH = 1280, 720  # or any other desired size\n",
    "\n",
    "        predicted_mask = read_and_draw_masks(predicted_mask_path)\n",
    "\n",
    "        ground_truth_mask = read_and_draw_masks(ground_truth_mask_path)\n",
    "\n",
    "        predicted_mask = cv2.resize(predicted_mask, (COMMON_WIDTH, COMMON_HEIGHT))\n",
    "        ground_truth_mask = cv2.resize(ground_truth_mask, (COMMON_WIDTH, COMMON_HEIGHT))\n",
    "\n",
    "        _, predicted_mask_bin = cv2.threshold(predicted_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        _, ground_truth_mask_bin = cv2.threshold(ground_truth_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        predicted_mask_bin = predicted_mask_bin / 255\n",
    "        ground_truth_mask_bin = ground_truth_mask_bin / 255\n",
    "        TP = np.float64(np.sum(np.logical_and(predicted_mask_bin == 1, ground_truth_mask_bin == 1)))\n",
    "        TN = np.float64(np.sum(np.logical_and(predicted_mask_bin == 0, ground_truth_mask_bin == 0)))\n",
    "        FP = np.float64(np.sum(np.logical_and(predicted_mask_bin == 1, ground_truth_mask_bin == 0)))\n",
    "        FN = np.float64(np.sum(np.logical_and(predicted_mask_bin == 0, ground_truth_mask_bin == 1)))\n",
    "\n",
    "\n",
    "        intersection = np.logical_and(predicted_mask_bin, ground_truth_mask_bin)\n",
    "        union = np.logical_or(predicted_mask_bin, ground_truth_mask_bin)\n",
    "        metrics['iou_scores'].append(np.sum(intersection) / np.sum(union))\n",
    "        metrics['pixel_accuracies'].append(pixel_accuracy(predicted_mask_bin, ground_truth_mask_bin))\n",
    "        precision, recall, f1, mcc, specificity = calculate_metrics(TP, FP, FN, TN)\n",
    "        metrics['precision_scores'].append(precision)\n",
    "        metrics['recall_scores'].append(recall)\n",
    "        metrics['f1_scores'].append(f1)\n",
    "        metrics['mcc_scores'].append(mcc)\n",
    "        metrics['specificity_scores'].append(specificity)\n",
    "\n",
    "    return metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prompt Optimization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_yolo_world(image_path, prompt, conf, model_size, save_image = False, save_label= True):\n",
    "\n",
    "    model = YOLO(model_size)  # or choose yolov8m/l-world.pt\n",
    "\n",
    "    model.set_classes([prompt])\n",
    "\n",
    "    results = model.predict(image_path,conf=conf, save=save_image, save_txt=save_label, verbose=False)\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time as t\n",
    "def optimize_confidence(prompt, model_size, gt_path, img_dir):\n",
    "    best_iou = 0\n",
    "    best_conf = 0\n",
    "    #number of decimal points in confidence\n",
    "    final_precision = 5\n",
    "    ubound = 0.1\n",
    "    lbound = 0.9\n",
    "    for precision in [x for x in range(final_precision)]:\n",
    "        for conf in [x / (10 ** precision) for x in range(int(lbound * (10 ** precision)), int(ubound * (10 ** precision)))]:\n",
    "            results = run_yolo_world(img_dir, prompt, conf, model_size)\n",
    "            metrics = process_files(results[0].save_dir+r\"/labels/\", gt_path)\n",
    "            #print(metrics)\n",
    "            iou = np.mean(metrics['iou_scores'])\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_conf = conf\n",
    "            print(f\"confidence: {conf}, IOU: {iou} (best: {best_iou})\")\n",
    "        print(f\"Best IOU at p{precision} is {best_iou} with confidence = {best_conf}\")\n",
    "        lbound = max(0, best_conf - (1 / (10 ** precision)))\n",
    "        ubound = min(0.9, best_conf + (1 / (10 ** precision)))\n",
    "        if (best_conf > (0.2*(10**precision))) and precision >=2:\n",
    "            print(f\"Final Result: Best IOU  is {best_iou} with confidence = {best_conf}\")\n",
    "            return best_iou, best_conf\n",
    "\n",
    "    return best_iou, best_conf\n",
    "\n",
    "def multi_optmize(img_dir, gt_label_dir, model_size, prompts):\n",
    "    print(\"Be sure to change the category folders and model size in each function!\")\n",
    "    t.sleep(2)\n",
    "    start = t.time()\n",
    "    best_iou = 0\n",
    "    for prompt in prompts:\n",
    "        print(f\"Trying prompt: '{prompt}'\")\n",
    "        iou, conf = optimize_confidence(prompt, model_size, gt_label_dir, img_dir)\n",
    "        if iou > best_iou:\n",
    "            best_iou = iou\n",
    "            best_conf = conf\n",
    "            best_prompt = prompt\n",
    "        print(f\"So far: best prompt is '{best_prompt}', conf is {best_conf}, resulting in {best_iou} IOU)\")\n",
    "    print(f\"\\n\\n\\n\\n\\nFinal Result: best prompt is '{best_prompt}', conf is {best_conf}, resulting in {best_iou} IOU)\")\n",
    "    print(f\"final time: {t.time() - start}\")\n",
    "    return {\"prompt\": best_prompt, \"conf\": best_conf, \"iou\": best_iou}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def optimize_prompts(prompts_file, gt_path, img_dir, save_file):\n",
    "\n",
    "    with  open(prompts_file, 'r') as file:\n",
    "        result_dict = {}\n",
    "        for x in file:\n",
    "            result_dict[x.strip()] = {}\n",
    "\n",
    "    #result_dict = dict.fromkeys(prompts,{})\n",
    "    for prompt in result_dict.keys():\n",
    "        print(f'Trying prompt: \"{prompt}\"')\n",
    "        model_size = 'yolov8l-worldv2.pt'\n",
    "        results = run_yolo_world(img_dir, prompt, 0.001, model_size)\n",
    "        inf_path= results[0].save_dir+r\"/labels/\"\n",
    "        metrics = process_files(inf_path, gt_path)\n",
    "        result_dict[prompt]['iou_scores'] = np.mean(metrics['iou_scores'])\n",
    "        print(f\"IOU for {prompt}: {result_dict[prompt]['iou_scores']}\")\n",
    "\n",
    "    results = sorted(list(result_dict.items()), key=lambda a:a[1]['iou_scores'], reverse=True)\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(TP, FP, FN, TN):\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    mcc = ((TP * TN) - (FP * FN)) / np.sqrt((TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)) if np.sqrt((TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)) > 0 else 0\n",
    "    specificity = TN / (TN + FP) if TN + FP > 0 else 0\n",
    "    return precision, recall, f1, mcc, specificity\n",
    "def pixel_accuracy(predicted, ground_truth):\n",
    "    correct = np.sum(predicted == ground_truth)\n",
    "    total = predicted.shape[0] * predicted.shape[1]\n",
    "    return correct / total\n",
    "\n",
    "def clean_labels_from_file(file_path, cleaning_threshold=0.5):\n",
    "    # Read the file and check if it has more than one line\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    if len(lines) > 1:\n",
    "        accepted_lines = []\n",
    "\n",
    "        # Process each line\n",
    "        for line in lines:\n",
    "            class_id, x, y, width, height = map(float, line.strip().split())\n",
    "            #if width * height < 0.9:\n",
    "            if (width*height)<cleaning_threshold:\n",
    "                accepted_lines.append(line)\n",
    "\n",
    "        # Overwrite the file with accepted lines\n",
    "        with open(file_path, 'w') as f:\n",
    "            for line in accepted_lines:\n",
    "                f.write(line)\n",
    "\n",
    "\n",
    "#Uses absolute boxes (NOT NORMALIZED)\n",
    "def read_and_draw_boxes(file_path, image_dim=(1280, 720)):\n",
    "    boxes = []\n",
    "    clean_labels_from_file(file_path, cleaning_threshold=0.2)\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            class_id, x, y, width, height = map(float, line.strip().split())\n",
    "            x1 = (x-(width/2))*image_dim[0]\n",
    "            x2 = (x+(width/2))*image_dim[0]\n",
    "            y1 = (y-(height/2))*image_dim[1]\n",
    "            y2 = (y+(height/2))*image_dim[1]\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "    image = Image.new('L', image_dim, 0)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box in boxes:\n",
    "        draw.rectangle(box, fill=255)\n",
    "        #draw.rectangle([1,1,20,20], fill=255)\n",
    "    image.save(\"test.jpg\")\n",
    "    return np.array(image, dtype=np.uint8)\n",
    "\n",
    "def calculate_pixel_metrics(mask1, mask2):\n",
    "    \"\"\"\n",
    "    Calculate IoU based on pixel values from two masks.\n",
    "    \"\"\"\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "def process_files(predicted_mask_dir, ground_truth_mask_dir):\n",
    "    predicted_files = os.listdir(ground_truth_mask_dir)\n",
    "    metrics = {\n",
    "        'iou_scores': [],\n",
    "        'pixel_accuracies': [],\n",
    "        'precision_scores': [],\n",
    "        'recall_scores': [],\n",
    "        'f1_scores': [],\n",
    "        'mcc_scores': [],\n",
    "        'specificity_scores': []\n",
    "    }\n",
    "\n",
    "    for fname in predicted_files:\n",
    "        predicted_mask_path = os.path.join(predicted_mask_dir, fname)\n",
    "        ground_truth_mask_path = os.path.join(ground_truth_mask_dir, os.path.splitext(fname)[0] + '.txt')\n",
    "        if not os.path.exists(predicted_mask_path):\n",
    "            metrics['iou_scores'].append(0)\n",
    "            metrics['pixel_accuracies'].append(0)\n",
    "            metrics['precision_scores'].append(0)\n",
    "            metrics['recall_scores'].append(0)\n",
    "            metrics['f1_scores'].append(0)\n",
    "            metrics['mcc_scores'].append(0)\n",
    "            metrics['specificity_scores'].append(0)\n",
    "            continue\n",
    "\n",
    "        predicted_mask = read_and_draw_boxes(predicted_mask_path)\n",
    "        ground_truth_mask = read_and_draw_boxes(ground_truth_mask_path)\n",
    "\n",
    "        COMMON_HEIGHT, COMMON_WIDTH = 1280, 720  # or any other desired size\n",
    "\n",
    "        predicted_mask = cv2.resize(predicted_mask, (COMMON_WIDTH, COMMON_HEIGHT))\n",
    "\n",
    "        ground_truth_mask = cv2.resize(ground_truth_mask, (COMMON_WIDTH, COMMON_HEIGHT))\n",
    "\n",
    "        _, predicted_mask_bin = cv2.threshold(predicted_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        _, ground_truth_mask_bin = cv2.threshold(ground_truth_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        predicted_mask_bin = predicted_mask_bin / 255\n",
    "        ground_truth_mask_bin = ground_truth_mask_bin / 255\n",
    "        TP = np.float64(np.sum(np.logical_and(predicted_mask_bin == 1, ground_truth_mask_bin == 1)))\n",
    "        TN = np.float64(np.sum(np.logical_and(predicted_mask_bin == 0, ground_truth_mask_bin == 0)))\n",
    "        FP = np.float64(np.sum(np.logical_and(predicted_mask_bin == 1, ground_truth_mask_bin == 0)))\n",
    "        FN = np.float64(np.sum(np.logical_and(predicted_mask_bin == 0, ground_truth_mask_bin == 1)))\n",
    "\n",
    "\n",
    "        intersection = np.logical_and(predicted_mask_bin, ground_truth_mask_bin)\n",
    "        union = np.logical_or(predicted_mask_bin, ground_truth_mask_bin)\n",
    "        IoU = calculate_pixel_metrics(predicted_mask_bin, ground_truth_mask_bin)\n",
    "        #metrics['iou_scores'].append(np.sum(intersection) / np.sum(union))\n",
    "        metrics['iou_scores'].append(IoU)\n",
    "        metrics['pixel_accuracies'].append(pixel_accuracy(predicted_mask_bin, ground_truth_mask_bin))\n",
    "        precision, recall, f1, mcc, specificity = calculate_metrics(TP, FP, FN, TN)\n",
    "        metrics['precision_scores'].append(precision)\n",
    "        metrics['recall_scores'].append(recall)\n",
    "        metrics['f1_scores'].append(f1)\n",
    "        metrics['mcc_scores'].append(mcc)\n",
    "        metrics['specificity_scores'].append(specificity)\n",
    "\n",
    "    return metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Berries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompts_file = r'C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\blueberry-prompts.txt'\n",
    "ground_truth_dir = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-berries\\train\\labels\"\n",
    "\n",
    "results = optimize_prompts(prompts_file,ground_truth_dir, r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-berries\\train\\images\", 'berry-results-dino.txt')\n",
    "\n",
    "top10 = [result[0] for result in results][0:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-berries\\train\\images\", r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-berries\\train\\labels\", 'yolov8s-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-berries\\train\\images\", r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-berries\\train\\labels\", 'yolov8m-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-berries\\train\\images\", r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-berries\\train\\labels\", 'yolov8l-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-berries\\train\\images\", r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-berries\\train\\labels\", 'yolov8x-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RedLeaf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompts_file = r'C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\red_leaf_plant_prompts.txt'\n",
    "ground_truth_dir = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\red-leaf-bounding-box-1\\train\\labels\"\n",
    "\n",
    "results = optimize_prompts(prompts_file,ground_truth_dir, r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\red-leaf-bounding-box-1\\train\\images\", 'redleaf-results-dino.txt')\n",
    "\n",
    "top10 = [result[0] for result in results][0:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\red-leaf-bounding-box-1\\train\\images\", r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\red-leaf-bounding-box-1\\train\\labels\", 'yolov8s-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\red-leaf-bounding-box-1\\train\\images\", r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\red-leaf-bounding-box-1\\train\\labels\", 'yolov8m-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\red-leaf-bounding-box-1\\train\\images\", r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\red-leaf-bounding-box-1\\train\\labels\", 'yolov8l-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\red-leaf-bounding-box-1\\train\\images\", r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\red-leaf-bounding-box-1\\train\\labels\", 'yolov8x-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Fescue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying prompt: \"Fescue grass patches\"\n",
      "Results saved to \u001B[1mruns\\detect\\predict454\u001B[0m\n",
      "2 labels saved to runs\\detect\\predict454\\labels\n",
      "IOU for Fescue grass patches: 0.010172084650566082\n",
      "Trying prompt: \"Fescue grass areas\"\n",
      "Results saved to \u001B[1mruns\\detect\\predict455\u001B[0m\n",
      "1 label saved to runs\\detect\\predict455\\labels\n",
      "IOU for Fescue grass areas: 0.007832504073556797\n",
      "Trying prompt: \"Fescue grass clusters\"\n",
      "Results saved to \u001B[1mruns\\detect\\predict456\u001B[0m\n",
      "4 labels saved to runs\\detect\\predict456\\labels\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\MECHAN~1\\AppData\\Local\\Temp/ipykernel_25960/1425747056.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mground_truth_dir\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34mr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\tiled-fescue-boxes-1\\train\\labels\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptimize_prompts\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprompts_file\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mground_truth_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34mr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\tiled-fescue-boxes-1\\train\\images\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'fescue-results-dino.txt'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mtop10\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mresult\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\MECHAN~1\\AppData\\Local\\Temp/ipykernel_25960/391031473.py\u001B[0m in \u001B[0;36moptimize_prompts\u001B[1;34m(prompts_file, gt_path, img_dir, save_file)\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrun_yolo_world\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprompt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.001\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m         \u001B[0minf_path\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave_dir\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34mr\"/labels/\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m         \u001B[0mmetrics\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprocess_files\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minf_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgt_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m         \u001B[0mresult_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mprompt\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'iou_scores'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'iou_scores'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"IOU for {prompt}: {result_dict[prompt]['iou_scores']}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\MECHAN~1\\AppData\\Local\\Temp/ipykernel_25960/1865724477.py\u001B[0m in \u001B[0;36mprocess_files\u001B[1;34m(predicted_mask_dir, ground_truth_mask_dir)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m         \u001B[0mpredicted_mask\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mread_and_draw_boxes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredicted_mask_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 94\u001B[1;33m         \u001B[0mground_truth_mask\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mread_and_draw_boxes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mground_truth_mask_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     95\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     96\u001B[0m         \u001B[0mCOMMON_HEIGHT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mCOMMON_WIDTH\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1280\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m720\u001B[0m  \u001B[1;31m# or any other desired size\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\MECHAN~1\\AppData\\Local\\Temp/ipykernel_25960/1865724477.py\u001B[0m in \u001B[0;36mread_and_draw_boxes\u001B[1;34m(file_path, image_dim)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mread_and_draw_boxes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimage_dim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1280\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m720\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m     \u001B[0mboxes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 40\u001B[1;33m     \u001B[0mclean_labels_from_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcleaning_threshold\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     41\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'r'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mline\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\MECHAN~1\\AppData\\Local\\Temp/ipykernel_25960/1865724477.py\u001B[0m in \u001B[0;36mclean_labels_from_file\u001B[1;34m(file_path, cleaning_threshold)\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[1;31m# Process each line\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mline\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mlines\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m             \u001B[0mclass_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwidth\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheight\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mline\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m             \u001B[1;31m#if width * height < 0.9:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mwidth\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mheight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m<\u001B[0m\u001B[0mcleaning_threshold\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "prompts_file = r'C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Fescue_prompts.txt'\n",
    "ground_truth_dir = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\tiled-fescue-boxes-1\\train\\labels\"\n",
    "\n",
    "results = optimize_prompts(prompts_file,ground_truth_dir, r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\tiled-fescue-boxes-1\\train\\images\", 'fescue-results-dino.txt')\n",
    "\n",
    "top10 = [result[0] for result in results][0:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(\n",
    "    r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\tiled-fescue-boxes-1\\train\\images\",\n",
    "    r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\tiled-fescue-boxes-1\\train\\labels\",\n",
    "    'yolov8s-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(\n",
    "    r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\tiled-fescue-boxes-1\\train\\images\",\n",
    "    r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\tiled-fescue-boxes-1\\train\\labels\",\n",
    "    'yolov8m-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(\n",
    "    r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\tiled-fescue-boxes-1\\train\\images\",\n",
    "    r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\tiled-fescue-boxes-1\\train\\labels\",\n",
    "    'yolov8l-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(\n",
    "    r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\tiled-fescue-boxes-1\\train\\images\",\n",
    "    r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\tiled-fescue-boxes-1\\train\\labels\",\n",
    "    'yolov8x-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Buds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompts_file = r'C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bud_prompts.txt'\n",
    "ground_truth_dir = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-buds-1\\train\\labels\"\n",
    "\n",
    "results = optimize_prompts(prompts_file,ground_truth_dir, r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-buds-1\\train\\images\", 'bud-results-dino.txt')\n",
    "\n",
    "top10 = [result[0] for result in results][0:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-buds-1\\train\\images\",\n",
    "    r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-buds-1\\train\\labels\",\n",
    "    'yolov8s-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-buds-1\\train\\images\",\n",
    "              r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-buds-1\\train\\labels\",\n",
    "              'yolov8m-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-buds-1\\train\\images\",\n",
    "              r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-buds-1\\train\\labels\",\n",
    "              'yolov8l-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_optmize(r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-buds-1\\train\\images\",\n",
    "              r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\bounding-buds-1\\train\\labels\",\n",
    "              'yolov8x-worldv2.pt', top10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AutoAnnotate With SAM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "paths=[r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\berries-1\\train\\images\", r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\red-leaf-1\\train\\images\", r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\fescue-1\\train\\images\", r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\buds-1\\train\\images\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "YW = ['yolov8s-worldv2.pt', 'yolov8m-worldv2.pt', 'yolov8l-worldv2.pt', 'yolov8x-worldv2.pt']\n",
    "prompt = [\n",
    "    ['a blue fruit','spherical blueberry','a single, round blueberry','a blue fruit'],\n",
    "    ['Bright red leaves contrasting with surrounding green leaves','a cluster of red leaves among green plants','a cluster of red leaves among green vegetation','A cluster of red leaves surrounded by green foliage'],\n",
    "    ['grass spots','Fescue grass regions','Fescue grass spots','Fescue grass regions'],\n",
    "    ['Bud with leaves','Bud with leaves','Bud with sprouting leaves','Bud with leaves']\n",
    "]\n",
    "conf = [[0.008,0.0012,0.04,0.0115],[0.037,0.01,0.014,0.01],[0.0004,0.0001,0.0,0.0023],[0.0012,0.007,0.0031,0.0028]]\n",
    "SAM_model = ['mobile_sam.pt','sam_b.pt','sam_l.pt']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bertimes = []\n",
    "rltimes = []\n",
    "budtimes = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mobile SAM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"YW with mobile on berries\")\n",
    "for i in range(4):\n",
    "    start = time.time()\n",
    "    auto_annotate(\n",
    "        data=paths[0],\n",
    "        det_model=YW[i],\n",
    "        sam_model=SAM_model[0],\n",
    "        device=\"cuda\",\n",
    "        output_dir=fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\berries\\YW_Mobile\\{YW[i]}\",\n",
    "        prompt=prompt[0][i],\n",
    "        confidence=conf[0][i],\n",
    "        box_threshold=.4\n",
    "    )\n",
    "    total = time.time()-start\n",
    "    print(f\"\\n\\nTime for {YW[i]}: {total}\")\n",
    "    bertimes.append(total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n YW with mobile on red leaf\")\n",
    "for i in range(4):\n",
    "    start = time.time()\n",
    "    auto_annotate(\n",
    "        data=paths[1],\n",
    "        det_model=YW[i],\n",
    "        sam_model=SAM_model[0],\n",
    "        device=\"cuda\",\n",
    "        output_dir=fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\red leaf\\YW_Mobile\\{YW[i]}\",\n",
    "        prompt=prompt[1][i],\n",
    "        confidence=conf[1][i],\n",
    "        box_threshold=.4\n",
    "    )\n",
    "    total = time.time()-start\n",
    "    print(f\"\\n\\nTime for {YW[i]}: {total}\")\n",
    "    rltimes.append(total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n YW with mobile on fescue\")\n",
    "for i in range(4):\n",
    "    start = time.time()\n",
    "    auto_annotate(\n",
    "        data=paths[2],\n",
    "        det_model=YW[i],\n",
    "        sam_model=SAM_model[0],\n",
    "        device=\"cuda\",\n",
    "        output_dir=fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\fescue\\YW_Mobile\\{YW[i]}\",\n",
    "        prompt=prompt[2][i],\n",
    "        confidence=conf[2][i],\n",
    "        box_threshold=0.5\n",
    "    )\n",
    "    total = time.time()-start\n",
    "    print(f\"\\n\\nTime for {YW[i]}: {total}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n YW with mobile on buds\")\n",
    "for i in range(4):\n",
    "    start = time.time()\n",
    "    auto_annotate(\n",
    "        data=paths[3],\n",
    "        det_model=YW[i],\n",
    "        sam_model=SAM_model[0],\n",
    "        device=\"cuda\",\n",
    "        output_dir=fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\buds\\YW_Mobile\\{YW[i]}\",\n",
    "        prompt=prompt[3][i],\n",
    "        confidence=conf[3][i],\n",
    "        box_threshold=0.3\n",
    "    )\n",
    "    total = time.time()-start\n",
    "    print(f\"\\n\\nTime for {YW[i]}: {total}\")\n",
    "    budtimes.append(total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base SAM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"YW with Base on berries\")\n",
    "for i in range(4):\n",
    "    start = time.time()\n",
    "    auto_annotate(\n",
    "        data=paths[0],\n",
    "        det_model=YW[i],\n",
    "        sam_model=SAM_model[1],\n",
    "        device=\"cuda\",\n",
    "        output_dir=fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\berries\\YW_Base\\{YW[i]}\",\n",
    "        prompt=prompt[0][i],\n",
    "        confidence=conf[0][i],\n",
    "        box_threshold=0.4\n",
    "    )\n",
    "    total = time.time()-start\n",
    "    print(f\"\\n\\nTime for {YW[i]}: {total}\")\n",
    "    bertimes.append(total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n YW with Base on red leaf\")\n",
    "for i in range(4):\n",
    "    start = time.time()\n",
    "    auto_annotate(\n",
    "        data=paths[1],\n",
    "        det_model=YW[i],\n",
    "        sam_model=SAM_model[1],\n",
    "        device=\"cuda\",\n",
    "        output_dir=fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\red leaf\\YW_Base\\{YW[i]}\",\n",
    "        prompt=prompt[1][i],\n",
    "        confidence=conf[1][i],\n",
    "        box_threshold=0.5\n",
    "    )\n",
    "    total = time.time()-start\n",
    "    print(f\"\\n\\nTime for {YW[i]}: {total}\")\n",
    "    rltimes.append(total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n YW with Base on fescue\")\n",
    "for i in range(4):\n",
    "    start = time.time()\n",
    "    auto_annotate(\n",
    "        data=paths[2],\n",
    "        det_model=YW[i],\n",
    "        sam_model=SAM_model[1],\n",
    "        device=\"cuda\",\n",
    "        output_dir=fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\fescue\\YW_Base\\{YW[i]}\",\n",
    "        prompt=prompt[2][i],\n",
    "        confidence=conf[2][i],\n",
    "        box_threshold=0.4\n",
    "    )\n",
    "    total = time.time()-start\n",
    "    print(f\"\\n\\nTime for {YW[i]}: {total}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n YW with Base on buds\")\n",
    "for i in range(4):\n",
    "    start = time.time()\n",
    "    auto_annotate(\n",
    "        data=paths[3],\n",
    "        det_model=YW[i],\n",
    "        sam_model=SAM_model[1],\n",
    "        device=\"cuda\",\n",
    "        output_dir=fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\buds\\YW_Base\\{YW[i]}\",\n",
    "        prompt=prompt[3][i],\n",
    "        confidence=conf[3][i],\n",
    "        box_threshold=0.25\n",
    "    )\n",
    "    total = time.time()-start\n",
    "    print(f\"\\n\\nTime for {YW[i]}: {total}\")\n",
    "    budtimes.append(total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SAM Large"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"YW with Large on berries\")\n",
    "for i in range(4):\n",
    "    start = time.time()\n",
    "    auto_annotate(\n",
    "        data=paths[0],\n",
    "        det_model=YW[i],\n",
    "        sam_model=SAM_model[2],\n",
    "        device=\"cuda\",\n",
    "        output_dir=fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\berries\\YW_Large\\{YW[i]}\",\n",
    "        prompt=prompt[0][i],\n",
    "        confidence=conf[0][i],\n",
    "        box_threshold=0.4\n",
    "    )\n",
    "    total = time.time() - start\n",
    "    print(f\"\\n\\nTime for {YW[i]}: {total}\")\n",
    "    bertimes.append(total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n YW with Large on red leaf\")\n",
    "for i in range(4):\n",
    "    start = time.time()\n",
    "    auto_annotate(\n",
    "        data=paths[1],\n",
    "        det_model=YW[i],\n",
    "        sam_model=SAM_model[2],\n",
    "        device=\"cuda\",\n",
    "        output_dir=fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\red leaf\\YW_Large\\{YW[i]}\",\n",
    "        prompt=prompt[1][i],\n",
    "        confidence=conf[1][i],\n",
    "        box_threshold=0.5\n",
    "    )\n",
    "    total = time.time() - start\n",
    "    print(f\"\\n\\nTime for {YW[i]}: {total}\")\n",
    "    rltimes.append(total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n YW with Large on fescue\")\n",
    "for i in range(4):\n",
    "    start = time.time()\n",
    "    auto_annotate(\n",
    "        data=paths[2],\n",
    "        det_model=YW[i],\n",
    "        sam_model=SAM_model[2],\n",
    "        device=\"cuda\",\n",
    "        output_dir=fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\fescue\\YW_Large\\{YW[i]}\",\n",
    "        prompt=prompt[2][i],\n",
    "        confidence=conf[2][i],\n",
    "        box_threshold=0.4\n",
    "    )\n",
    "    total = time.time() - start\n",
    "    print(f\"\\n\\nTime for {YW[i]}: {total}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n YW with Large on buds\")\n",
    "for i in range(4):\n",
    "    start = time.time()\n",
    "    auto_annotate(\n",
    "        data=paths[3],\n",
    "        det_model=YW[i],\n",
    "        sam_model=SAM_model[2],\n",
    "        device=\"cuda\",\n",
    "        output_dir=fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\buds\\YW_Large\\{YW[i]}\",\n",
    "        prompt=prompt[3][i],\n",
    "        confidence=conf[3][i],\n",
    "        box_threshold=0.25\n",
    "    )\n",
    "    total = time.time() - start\n",
    "    print(f\"\\n\\nTime for {YW[i]}: {total}\")\n",
    "    budtimes.append(total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for time in bertimes:\n",
    "    print(time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for time in rltimes:\n",
    "    print(time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for time in budtimes:\n",
    "    print(time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Segmentation Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 201
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sam_models = ['YW_Base','YW_Mobile','YW_Large']\n",
    "categories = ['berries','fescue','red leaf','buds']\n",
    "folders = {'berries':'berries-1', 'red leaf':'red-leaf-1','fescue':'fescue-1','buds':'buds-1'}\n",
    "\n",
    "for category in categories:\n",
    "    for sam_model in sam_models:\n",
    "        for yolo_model in YW:\n",
    "            metrics = process_files_seg(fr\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\Worldly_SAM\\trials\\{category}\\{sam_model}\\{yolo_model}\", fr'C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\{folders[category]}\\train\\labels')\n",
    "            for score in metrics['iou_scores']:\n",
    "                print(score)\n",
    "            print(rf\"{category}\\{yolo_model}\\{sam_model}: Mean IOU = {np.mean(metrics['iou_scores'])}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tiling Tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.42, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in tiled-fescue-boxes-1 to yolov8:: 100%|██████████| 847/847 [00:00<00:00, 4277.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to tiled-fescue-boxes-1 in yolov8:: 100%|██████████| 18/18 [00:00<00:00, 2249.89it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"8t6x218rPQnJEC3RbLZq\")\n",
    "project = rf.workspace(\"auto-annotate-2\").project(\"tiled-fescue-boxes\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1mruns\\detect\\predict438\u001B[0m\n",
      "20 labels saved to runs\\detect\\predict438\\labels\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
