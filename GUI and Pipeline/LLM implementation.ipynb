{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "from groundingdino.util.inference import load_model, load_image, predict\n",
    "import cv2\n",
    "import torch\n",
    "import csv\n",
    "from ultralytics import SAM\n",
    "from pathlib import Path\n",
    "import time as t\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from PyQt5 import QtWidgets, QtGui, QtCore\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def clean_labels(boxes, max_area):\n",
    "    clean_boxes = []\n",
    "    box_list = boxes.tolist()\n",
    "    for box in box_list:\n",
    "        # if width * height < 0.9, add box to list.\n",
    "        if (box[2] * box[3]) < max_area:\n",
    "            clean_boxes.append(box)\n",
    "    if len(clean_boxes) < 2:\n",
    "        return boxes\n",
    "    return torch.FloatTensor(clean_boxes)\n",
    "\n",
    "def load_dino_model(model_size='swint'):\n",
    "    #choose swinb or swint\n",
    "    if model_size == 'swint':\n",
    "        config_path = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\GroundingDINO\\groundingdino\\config\\GroundingDINO_SwinT_OGC.py\"\n",
    "        checkpoint_path = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\GroundingDINO\\weights\\groundingdino_swint_ogc.pth\"\n",
    "    elif model_size == 'swinb':\n",
    "        checkpoint_path = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\GroundingDINO\\weights\\groundingdino_swinb_cogcoor.pth\"\n",
    "        config_path = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\GroundingDINO\\groundingdino\\config\\GroundingDINO_SwinB_cfg.py\"\n",
    "\n",
    "    model = load_model(config_path, checkpoint_path)\n",
    "    return model\n",
    "\n",
    "def run_dino_from_model(model, img_path, prompt, box_threshold, text_threshold, maxarea=0.7, save_dir=\"DINO-labels\"):\n",
    "    image_source, image = load_image(img_path)\n",
    "    boxes, accuracy, obj_name = predict(model=model, image=image, caption=prompt, box_threshold=box_threshold,\n",
    "                                        text_threshold=text_threshold)\n",
    "\n",
    "    #Convert boxes from YOLOv8 format to xyxy\n",
    "    img_height, img_width = cv2.imread(img_path).shape[:2]\n",
    "    clean_boxes = clean_labels(boxes, maxarea)\n",
    "    absolute_boxes = [[(box[0] - (box[2] / 2)) * img_width,\n",
    "                       (box[1] - (box[3] / 2)) * img_height,\n",
    "                       (box[0] + (box[2] / 2)) * img_width,\n",
    "                       (box[1] + (box[3] / 2)) * img_height] for box in clean_boxes.tolist()]\n",
    "    save_labels = True\n",
    "    if save_labels:\n",
    "        clean_boxes = clean_boxes.tolist()\n",
    "        for x in clean_boxes:\n",
    "            x.insert(0, 0)\n",
    "        with open(f'{save_dir}/{os.path.splitext(os.path.basename(img_path))[0]}.txt', 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=' ')\n",
    "            writer.writerows(clean_boxes)\n",
    "    return absolute_boxes\n",
    "\n",
    "def save_masks(sam_results, output_dir):\n",
    "    segments = sam_results[0].masks.xyn\n",
    "    with open(f\"{Path(output_dir) / Path(sam_results[0].path).stem}.txt\", \"w\") as f:\n",
    "        for i in range(len(segments)):\n",
    "            s = segments[i]\n",
    "            if len(s) == 0:\n",
    "                continue\n",
    "            segment = map(str, segments[i].reshape(-1).tolist())\n",
    "            f.write(f\"0 \" + \" \".join(segment) + \"\\n\")\n",
    "\n",
    "def run_image(DINO, img_dir, output_dir, prompt, conf, box_threshold, save_dir):\n",
    "    sam_model = \"sam2_t.pt\"\n",
    "    dino_model = \"swint\"\n",
    "    start = t.time()\n",
    "    fname = os.path.basename(img_dir)\n",
    "    path = img_dir\n",
    "    boxes = run_dino_from_model(DINO, img_dir, prompt, conf, 0.1, box_threshold, save_dir=save_dir)\n",
    "    model = SAM(sam_model)\n",
    "    sam_results = model(img_dir, model=sam_model, bboxes=boxes, verbose=False)\n",
    "    save_masks(sam_results, output_dir)\n",
    "\n",
    "    print(f\"Completed in: {t.time() - start} seconds, masks saved in {output_dir}\")\n",
    "    return sam_results\n",
    "\n",
    "def adjust_masks(sam_results):\n",
    "    result = sam_results[0]\n",
    "\n",
    "    masks = result.masks.data.cpu().numpy()  # masks, (N, H, W)\n",
    "    masks = np.moveaxis(masks, 0, -1)  # masks, (H, W, N)\n",
    "    masks = np.moveaxis(masks, -1, 0)  # masks, (N, H, W)\n",
    "\n",
    "    return masks\n",
    "\n",
    "def overlay_with_borders(image, mask, color, thickness=2):\n",
    "    # Convert mask to uint8 type\n",
    "    mask_uint8 = (mask * 255).astype(np.uint8)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw contours on the image\n",
    "    cv2.drawContours(image, contours, -1, color, thickness)\n",
    "    return image\n",
    "\n",
    "def draw_boxes_on_image(image, boxes):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes on the image using absolute coordinates.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The original image.\n",
    "        boxes (list): List of bounding boxes in the format [x1, y1, x2, y2].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Image with bounding boxes drawn on it.\n",
    "    \"\"\"\n",
    "    # Convert the OpenCV image (BGR) to PIL for drawing\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Create a drawing object\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    # Iterate over the list of boxes and draw them\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=(255, 0, 255), width=2)  # Drawing a rectangle with purple border\n",
    "\n",
    "    # Convert back to OpenCV format for display\n",
    "    return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def optimize_prompts(prompts_file, gt_path, img_dir, save_file, threshold, DINO):\n",
    "    inf_path = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\AutoAnnotate\\GUI and Pipeline\\DINO-labels\"\n",
    "    if not os.path.exists(inf_path):\n",
    "        try:\n",
    "            os.makedirs(inf_path)\n",
    "            print(f\"Directory '{inf_path}' created as it was missing.\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    with open(prompts_file, 'r') as file:\n",
    "        result_dict = {}\n",
    "        for x in file:\n",
    "            result_dict[x.strip()] = {}\n",
    "\n",
    "    # result_dict = dict.fromkeys(prompts,{})\n",
    "    for prompt in result_dict.keys():\n",
    "        print(f'Trying prompt: \"{prompt}\"')\n",
    "\n",
    "        box_threshold = 0.3\n",
    "        text_threshold = 0.1\n",
    "        model_size = 'swint'\n",
    "        run_dino_from_model(DINO, img_dir, prompt, box_threshold, text_threshold, maxarea=threshold)\n",
    "\n",
    "        metrics = process_file(inf_path, gt_path, threshold=threshold)\n",
    "\n",
    "        result_dict[prompt]['iou_scores'] = np.mean(metrics['iou_scores'])\n",
    "\n",
    "    results = sorted(list(result_dict.items()), key=lambda a: a[1]['iou_scores'], reverse=True)\n",
    "    print(results)\n",
    "\n",
    "    with open(save_file, 'w') as output:\n",
    "        for prompt_stats in results:\n",
    "            output.write(str(prompt_stats) + '\\n')\n",
    "\n",
    "    return results\n",
    "\n",
    "def calculate_metrics(tp, fp, fn, tn):\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    mcc = ((tp * tn) - (fp * fn)) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) \\\n",
    "        if np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if tn + fp > 0 else 0\n",
    "    return precision, recall, f1, mcc, specificity\n",
    "\n",
    "def read_and_draw_boxes(file_path, image_dim=(1280, 720)):\n",
    "    boxes = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            class_id, x, y, width, height = map(float, line.strip().split())\n",
    "            x1 = (x-(width/2))*image_dim[0]\n",
    "            x2 = (x+(width/2))*image_dim[0]\n",
    "            y1 = (y-(height/2))*image_dim[1]\n",
    "            y2 = (y+(height/2))*image_dim[1]\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "    image = Image.new('L', image_dim, 0)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box in boxes:\n",
    "        draw.rectangle(box, fill=255)\n",
    "        #draw.rectangle([1,1,20,20], fill=255)\n",
    "    #image.save(\"test.jpg\")\n",
    "    return np.array(image, dtype=np.uint8)\n",
    "\n",
    "def clean_labels_from_file(file_path, cleaning_threshold=0.6):\n",
    "    # Read the file and check if it has more than one line\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    if len(lines) > 1:\n",
    "        accepted_lines = []\n",
    "\n",
    "        # Process each line\n",
    "        for line in lines:\n",
    "            class_id, x, y, width, height = map(float, line.strip().split())\n",
    "            # if width * height < 0.9:\n",
    "            if (width * height) < cleaning_threshold:\n",
    "                accepted_lines.append(line)\n",
    "\n",
    "        # Overwrite the file with accepted lines\n",
    "        with open(file_path, 'w') as f:\n",
    "            if len(accepted_lines) > 0:\n",
    "                for line in accepted_lines:\n",
    "                    f.write(line)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def draw_boxes(boxes, image_dim=(1280, 720)):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes directly from a list of absolute boxes.\n",
    "\n",
    "    Parameters:\n",
    "    boxes (list): List of absolute box coordinates in xyxy format.\n",
    "    image_dim (tuple): Dimensions of the output image (width, height).\n",
    "\n",
    "    Returns:\n",
    "    np.array: Binary image with boxes drawn.\n",
    "    \"\"\"\n",
    "    # Create a blank image to draw the boxes\n",
    "    image = Image.new('L', image_dim, 0)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Draw each box on the image\n",
    "    for box in boxes:\n",
    "        draw.rectangle(box, fill=255)\n",
    "\n",
    "    return np.array(image, dtype=np.uint8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def prompt_optimizer(prompts_file, gt_path, img_path, save_file, threshold, DINO):\n",
    "    # Ensure inference path exists\n",
    "    inf_path = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\AutoAnnotate\\GUI and Pipeline\\DINO-labels\"\n",
    "    os.makedirs(inf_path, exist_ok=True)\n",
    "\n",
    "    # Initialize result dictionary from prompt file\n",
    "    with open(prompts_file, 'r') as file:\n",
    "        result_dict = {x.strip(): {} for x in file}\n",
    "\n",
    "    # Process each prompt\n",
    "    for prompt in result_dict.keys():\n",
    "        print(f'Trying prompt: \"{prompt}\"')\n",
    "\n",
    "        # Run prediction and save labels\n",
    "        run_dino_from_model(DINO, img_path, prompt, box_threshold=0.3, text_threshold=0.1, maxarea=threshold)\n",
    "\n",
    "        # Process single predicted and ground truth file\n",
    "        predicted_mask_file = os.path.join(inf_path, f\"{os.path.splitext(os.path.basename(img_path))[0]}.txt\")\n",
    "        metrics = process_file(predicted_mask_file, gt_path, threshold)\n",
    "\n",
    "        # Save the IoU score for the prompt\n",
    "        result_dict[prompt]['iou_scores'] = np.mean(metrics['iou_scores'])\n",
    "\n",
    "    # Sort and save results\n",
    "    results = sorted(result_dict.items(), key=lambda a: a[1]['iou_scores'], reverse=True)\n",
    "    print(\"Results:\", results)\n",
    "\n",
    "    with open(save_file, 'w') as output:\n",
    "        for prompt_stats in results:\n",
    "            output.write(str(prompt_stats) + '\\n')\n",
    "\n",
    "    return results\n",
    "\n",
    "def process_file(predicted_mask_file, ground_truth_mask_file, threshold):\n",
    "    # Initialize metrics dictionary\n",
    "    metrics = {\n",
    "        'iou_scores': [],\n",
    "        'precision_scores': [],\n",
    "        'recall_scores': [],\n",
    "        'f1_scores': [],\n",
    "        'mcc_scores': [],\n",
    "        'specificity_scores': []\n",
    "    }\n",
    "\n",
    "    # Preprocess predicted mask\n",
    "    clean_labels_from_file(predicted_mask_file, threshold)\n",
    "    predicted_mask = read_and_draw_boxes(predicted_mask_file)\n",
    "    ground_truth_mask = read_and_draw_boxes(ground_truth_mask_file)\n",
    "\n",
    "    # Convert masks to binary\n",
    "    _, predicted_mask_bin = cv2.threshold(predicted_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    _, ground_truth_mask_bin = cv2.threshold(ground_truth_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    predicted_mask_bin = predicted_mask_bin / 255\n",
    "    ground_truth_mask_bin = ground_truth_mask_bin / 255\n",
    "\n",
    "    # Calculate true positives, true negatives, false positives, and false negatives\n",
    "    tp = np.float64(np.sum(np.logical_and(predicted_mask_bin == 1, ground_truth_mask_bin == 1)))\n",
    "    tn = np.float64(np.sum(np.logical_and(predicted_mask_bin == 0, ground_truth_mask_bin == 0)))\n",
    "    fp = np.float64(np.sum(np.logical_and(predicted_mask_bin == 1, ground_truth_mask_bin == 0)))\n",
    "    fn = np.float64(np.sum(np.logical_and(predicted_mask_bin == 0, ground_truth_mask_bin == 1)))\n",
    "\n",
    "    # Calculate metrics\n",
    "    intersection = np.logical_and(predicted_mask_bin, ground_truth_mask_bin)\n",
    "    union = np.logical_or(predicted_mask_bin, ground_truth_mask_bin)\n",
    "    metrics['iou_scores'].append(np.sum(intersection) / np.sum(union))\n",
    "    # Calculate precision, recall, f1-score, MCC, and specificity\n",
    "    precision, recall, f1, mcc, specificity = calculate_metrics(tp, fp, fn, tn)\n",
    "    metrics['precision_scores'].append(precision)\n",
    "    metrics['recall_scores'].append(recall)\n",
    "    metrics['f1_scores'].append(f1)\n",
    "    metrics['mcc_scores'].append(mcc)\n",
    "    metrics['specificity_scores'].append(specificity)\n",
    "    #print(metrics['iou_scores'])\n",
    "    return metrics\n",
    "\n",
    "def process_mask_arrays(predicted_mask_array, ground_truth_mask_array):\n",
    "    # Resize predicted mask to match the ground truth mask's dimensions\n",
    "    if predicted_mask_array.shape != ground_truth_mask_array.shape:\n",
    "        predicted_mask_array = cv2.resize(predicted_mask_array, (ground_truth_mask_array.shape[1], ground_truth_mask_array.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Initialize metrics dictionary\n",
    "    metrics = {\n",
    "        'iou_scores': [],\n",
    "        'pixel_accuracies': [],\n",
    "        'precision_scores': [],\n",
    "        'recall_scores': [],\n",
    "        'f1_scores': [],\n",
    "        'mcc_scores': [],\n",
    "        'specificity_scores': []\n",
    "    }\n",
    "\n",
    "    # Convert masks to binary based on threshold\n",
    "    _, predicted_mask_bin = cv2.threshold(predicted_mask_array, 127, 255, cv2.THRESH_BINARY)\n",
    "    _, ground_truth_mask_bin = cv2.threshold(ground_truth_mask_array, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Normalize binary masks for calculation\n",
    "    predicted_mask_bin = predicted_mask_bin / 255\n",
    "    ground_truth_mask_bin = ground_truth_mask_bin / 255\n",
    "\n",
    "    # Calculate true positives, true negatives, false positives, and false negatives\n",
    "    tp = np.float64(np.sum(np.logical_and(predicted_mask_bin == 1, ground_truth_mask_bin == 1)))\n",
    "    tn = np.float64(np.sum(np.logical_and(predicted_mask_bin == 0, ground_truth_mask_bin == 0)))\n",
    "    fp = np.float64(np.sum(np.logical_and(predicted_mask_bin == 1, ground_truth_mask_bin == 0)))\n",
    "    fn = np.float64(np.sum(np.logical_and(predicted_mask_bin == 0, ground_truth_mask_bin == 1)))\n",
    "\n",
    "    # Calculate IoU and pixel accuracy\n",
    "    intersection = np.logical_and(predicted_mask_bin, ground_truth_mask_bin)\n",
    "    union = np.logical_or(predicted_mask_bin, ground_truth_mask_bin)\n",
    "    metrics['iou_scores'].append(np.sum(intersection) / np.sum(union))\n",
    "    metrics['pixel_accuracies'].append(pixel_accuracy(predicted_mask_bin, ground_truth_mask_bin))\n",
    "\n",
    "    # Calculate precision, recall, f1-score, MCC, and specificity\n",
    "    precision, recall, f1, mcc, specificity = calculate_metrics(tp, fp, fn, tn)\n",
    "    metrics['precision_scores'].append(precision)\n",
    "    metrics['recall_scores'].append(recall)\n",
    "    metrics['f1_scores'].append(f1)\n",
    "    metrics['mcc_scores'].append(mcc)\n",
    "    metrics['specificity_scores'].append(specificity)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def confidence_optimizer(prompt, DINO, gt_path, img_path, threshold):\n",
    "    inf_path = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\AutoAnnotate\\GUI and Pipeline\\DINO-labels\"\n",
    "    os.makedirs(inf_path, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "    best_iou = 0\n",
    "    best_conf = 0\n",
    "    final_precision = 5  # Number of decimal points in confidence\n",
    "    ubound = 0.9\n",
    "    lbound = 0.0\n",
    "    image = cv2.imread(img_path)\n",
    "    shape = image.shape\n",
    "    # Loop over precision levels\n",
    "    for precision in range(1, final_precision + 1):\n",
    "        esc = 0  # Escape counter to break if no improvement\n",
    "\n",
    "        # Range of confidence thresholds for the current precision level\n",
    "        for conf in [x / (10 ** precision) for x in range(int(lbound * (10 ** precision)), int(ubound * (10 ** precision)))]:\n",
    "            # Run the model with the current confidence threshold\n",
    "            box_threshold = conf\n",
    "            text_threshold = 0.01\n",
    "            boxes = run_dino_from_model(DINO, img_path, prompt, box_threshold, text_threshold)\n",
    "            pred_masks = draw_boxes(boxes, (shape[1], shape[0]))\n",
    "            gt_masks = read_and_draw_boxes(gt_path)\n",
    "            # Process the predicted and ground truth files for IoU calculation\n",
    "            #predicted_mask_file = os.path.join(inf_path, f\"{os.path.splitext(os.path.basename(img_path))[0]}.txt\")\n",
    "            #metrics = process_file(predicted_mask_file, gt_path, threshold)\n",
    "\n",
    "            metrics = process_mask_arrays(pred_masks, gt_masks)\n",
    "            iou = np.mean(metrics['iou_scores'])\n",
    "            # Update the best IoU and confidence threshold if the current IoU is higher\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_conf = conf\n",
    "                esc = 0  # Reset escape counter if improvement found\n",
    "            else:\n",
    "                esc += 1\n",
    "                # Exit loop early if no improvement found for multiple tries\n",
    "                if esc > 2 * precision:\n",
    "                    break\n",
    "\n",
    "            print(f\"Confidence: {conf}, IoU: {iou} (Best IoU: {best_iou})\")\n",
    "\n",
    "        print(f\"Best IoU at precision {precision} is {best_iou} with confidence = {best_conf}\")\n",
    "\n",
    "        # Adjust bounds based on best confidence found at the current precision level\n",
    "        lbound = max(0, best_conf - (1 / (10 ** precision)))\n",
    "        ubound = min(0.9, best_conf + (1 / (10 ** precision)))\n",
    "\n",
    "        # Early exit condition based on best confidence stability\n",
    "        if (best_conf > (0.2 * (10 ** precision))) and precision >= 2:\n",
    "            print(f\"Final Result: Best IoU is {best_iou} with confidence = {best_conf}\")\n",
    "            return best_iou, best_conf\n",
    "\n",
    "    return best_iou, best_conf\n",
    "\n",
    "def multi_optimizer(img_dir, gt_label_dir, DINO, prompts, threshold=0.9):\n",
    "    start = t.time()\n",
    "    best_iou = 0\n",
    "    best_prompt = \"\"\n",
    "    best_conf = 0\n",
    "    for prompt in prompts:\n",
    "        print(f\"Trying prompt: '{prompt}'\")\n",
    "        iou, conf = confidence_optimizer(prompt, DINO, gt_label_dir, img_dir, threshold)\n",
    "        if iou > best_iou:\n",
    "            best_iou = iou\n",
    "            best_conf = conf\n",
    "            best_prompt = prompt\n",
    "        print(f\"So far: best prompt is '{best_prompt}', conf is {best_conf}, resulting in {best_iou} IOU)\")\n",
    "    print(f\"\\n\\n\\n\\n\\nFinal Result: best prompt is '{best_prompt}', conf is {best_conf}, resulting in {best_iou} IOU)\")\n",
    "    print(f\"final time: {t.time() - start}\")\n",
    "    return {\"prompt\": best_prompt, \"conf\": best_conf, \"iou\": best_iou}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files sorted by line count: ['IMG_9355_jpg.rf.40d4de298491188a33bcdfd995d9e855.txt', 'IMG_9379_jpg.rf.42c280b08420d4271486e3cdebe8a30e.txt', 'IMG_9331_jpg.rf.20009327b80c55eec840b8b4f5cddf57.txt', 'IMG_9383_jpg.rf.7af81e391f70df26bca8c741d75bcf24.txt', 'IMG_9387_jpg.rf.9ae726fc1ddc490013a19db8c1c2a1f1.txt', 'IMG_9394_jpg.rf.93cd662dac6324bfa4ef17b55494eaf7.txt']\n"
     ]
    }
   ],
   "source": [
    "def sort_largest_file(folder):\n",
    "    # Dictionary to store file names and their line counts\n",
    "    file_line_counts = {}\n",
    "\n",
    "    # Iterate through files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Check if the file is a .txt file\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            # Open the file and count lines\n",
    "            with open(file_path, 'r') as file:\n",
    "                line_count = sum(1 for line in file)\n",
    "            # Add the file and line count to the dictionary\n",
    "            file_line_counts[file_name] = line_count\n",
    "        else:\n",
    "            print(\"File encountered not in .txt format.\")\n",
    "    # Sort files by line count in descending order and return as list of file names\n",
    "    sorted_files = sorted(file_line_counts, key=file_line_counts.get, reverse=True)\n",
    "    return sorted_files\n",
    "\n",
    "# Usage\n",
    "folder_path = r'C:\\Users\\Mechanized Systems\\DataspellProjects\\AutoAnnotate\\autoannotate study\\berries-bounding-box-1\\train\\gen labels'\n",
    "image_folder_path = r'C:\\Users\\Mechanized Systems\\DataspellProjects\\AutoAnnotate\\autoannotate study\\berries-bounding-box-1\\train\\images'\n",
    "sorted_txt_files = sort_largest_file(folder_path)\n",
    "print(\"Files sorted by line count:\", sorted_txt_files)\n",
    "reference_txt = folder_path + '\\\\' + sorted_txt_files[0]\n",
    "reference_image = image_folder_path + '\\\\' + sorted_txt_files[0].split(\".txt\")[0] + \".jpg\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "box_threshold = 0.9\n",
    "DINO = load_dino_model()\n",
    "prompts_file = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\blueberry-prompts.txt\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying prompt: \"blueberry\"\n",
      "Trying prompt: \"a blueberry\"\n",
      "Trying prompt: \"single blueberry\"\n",
      "Trying prompt: \"a single blueberry\"\n",
      "Trying prompt: \"a single, round blueberry\"\n",
      "Trying prompt: \"single, round blueberry\"\n",
      "Trying prompt: \"individual blueberry\"\n",
      "Trying prompt: \"an individual blueberry\"\n",
      "Trying prompt: \"one blueberries\"\n",
      "Trying prompt: \"small blue sphere\"\n",
      "Trying prompt: \"a small blue sphere\"\n",
      "Trying prompt: \"a small blue berry\"\n",
      "Trying prompt: \"a blueberry among a patch of green leaves\"\n",
      "Trying prompt: \"a wild blueberry\"\n",
      "Trying prompt: \"wild blueberry\"\n",
      "Trying prompt: \"single  wild blueberry\"\n",
      "Trying prompt: \"a single wild blueberry\"\n",
      "Trying prompt: \"a single, round  wild blueberry\"\n",
      "Trying prompt: \"blueberries\"\n",
      "Trying prompt: \"a blue berry\"\n",
      "Trying prompt: \"blue berry\"\n",
      "Trying prompt: \"a small blueberry\"\n",
      "Trying prompt: \"blueberry among a patch of green leaves\"\n",
      "Trying prompt: \"a round blueberry among a patch of green leaves\"\n",
      "Trying prompt: \"a blue sphere  among a patch of green leaves\"\n",
      "Trying prompt: \"blueberry in leaves\"\n",
      "Trying prompt: \"a blueberry in leaves\"\n",
      "Trying prompt: \"one individual blueberry\"\n",
      "Trying prompt: \"one blueberry\"\n",
      "Trying prompt: \"one round, blue berry\"\n",
      "Trying prompt: \"one round, blue sphere\"\n",
      "Trying prompt: \"one blueberry in a field of green leaves\"\n",
      "Trying prompt: \"blue sphere\"\n",
      "Trying prompt: \"a blue fruit\"\n",
      "Trying prompt: \"a blueberry in the foreground or background of a green field\"\n",
      "Trying prompt: \"blueberry in the background of a green field\"\n",
      "Trying prompt: \"a blueberry in the background of a green field\"\n",
      "Trying prompt: \"a blueberry in the background of a leafy field\"\n",
      "Trying prompt: \"blueberry in the background of a leafy field\"\n",
      "Trying prompt: \"Round Blueberry\"\n",
      "Trying prompt: \"Spherical Blueberry\"\n",
      "Trying prompt: \"Globular Blueberry\"\n",
      "Trying prompt: \"Plump Blueberry\"\n",
      "Trying prompt: \"Tiny Blueberry\"\n",
      "Trying prompt: \"Compact Blueberry\"\n",
      "Trying prompt: \"Smooth Blueberry\"\n",
      "Trying prompt: \"Egg-shaped Blueberry\"\n",
      "Trying prompt: \"Oval Blueberry\"\n",
      "Trying prompt: \"Perfectly-formed Blueberry\"\n",
      "Trying prompt: \"Circular Blueberry\"\n",
      "Trying prompt: \"Sphere-like Blueberry\"\n",
      "Trying prompt: \"Bulbous Blueberry\"\n",
      "Trying prompt: \"Curved Blueberry\"\n",
      "Trying prompt: \"Rounded Blueberry\"\n",
      "Trying prompt: \"Uniform Blueberry\"\n",
      "Trying prompt: \"Well-rounded Blueberry\"\n",
      "Trying prompt: \"Balanced Blueberry\"\n",
      "Trying prompt: \"Symmetrical Blueberry\"\n",
      "Trying prompt: \"Neat Blueberry\"\n",
      "Trying prompt: \"all blueberries\"\n",
      "Results: [('blue sphere', {'iou_scores': 0.9802219210570896}), ('blueberries', {'iou_scores': 0.9769146678670182}), ('Neat Blueberry', {'iou_scores': 0.9758431305243285}), ('blueberry', {'iou_scores': 0.9727292248228473}), ('wild blueberry', {'iou_scores': 0.9680983437741354}), ('blue berry', {'iou_scores': 0.9625805089219723}), ('Spherical Blueberry', {'iou_scores': 0.9560951522177852}), ('Symmetrical Blueberry', {'iou_scores': 0.9558148513577281}), ('Globular Blueberry', {'iou_scores': 0.9550202698354818}), ('Uniform Blueberry', {'iou_scores': 0.954891572467343}), ('Compact Blueberry', {'iou_scores': 0.9538190943995195}), ('Plump Blueberry', {'iou_scores': 0.9525741766499206}), ('Circular Blueberry', {'iou_scores': 0.9498475675211473}), ('single blueberry', {'iou_scores': 0.9496758126153978}), ('Balanced Blueberry', {'iou_scores': 0.9475166410650282}), ('Rounded Blueberry', {'iou_scores': 0.9469921422130619}), ('Oval Blueberry', {'iou_scores': 0.9466271630383443}), ('Curved Blueberry', {'iou_scores': 0.9461929367553487}), ('a wild blueberry', {'iou_scores': 0.9460413946619294}), ('single  wild blueberry', {'iou_scores': 0.9459401434153463}), ('individual blueberry', {'iou_scores': 0.9456610416935034}), ('Smooth Blueberry', {'iou_scores': 0.9448666752544119}), ('Round Blueberry', {'iou_scores': 0.9427325081657212}), ('a blue fruit', {'iou_scores': 0.9420188391038696}), ('Tiny Blueberry', {'iou_scores': 0.9412812915968912}), ('all blueberries', {'iou_scores': 0.9403313514314128}), ('a blue berry', {'iou_scores': 0.9397300716997048}), ('Bulbous Blueberry', {'iou_scores': 0.939649619992271}), ('a blueberry', {'iou_scores': 0.9389515172063062}), ('Egg-shaped Blueberry', {'iou_scores': 0.9347816744026131}), ('a small blue berry', {'iou_scores': 0.9303079416531604}), ('a small blueberry', {'iou_scores': 0.9162432739511651}), ('small blue sphere', {'iou_scores': 0.8914026189010802}), ('an individual blueberry', {'iou_scores': 0.877675710318308}), ('one blueberry', {'iou_scores': 0.8669324747873179}), ('a single blueberry', {'iou_scores': 0.8184789386543961}), ('blueberry in leaves', {'iou_scores': 0.7884591260715033}), ('Sphere-like Blueberry', {'iou_scores': 0.7813633145235694}), ('Well-rounded Blueberry', {'iou_scores': 0.7628978439425051}), ('a single wild blueberry', {'iou_scores': 0.714744069645569}), ('Perfectly-formed Blueberry', {'iou_scores': 0.6888045540796964}), ('one round, blue berry', {'iou_scores': 0.6686425482544035}), ('single, round blueberry', {'iou_scores': 0.6380623280220132}), ('one blueberries', {'iou_scores': 0.5761079249217935}), ('a small blue sphere', {'iou_scores': 0.4079842539899876}), ('a blueberry in leaves', {'iou_scores': 0.400414007981391}), ('one individual blueberry', {'iou_scores': 0.3750885098165433}), ('a single, round blueberry', {'iou_scores': 0.3632141398069108}), ('a single, round  wild blueberry', {'iou_scores': 0.32246423508184047}), ('a blueberry in the background of a green field', {'iou_scores': 0.31759002476871945}), ('a blueberry in the background of a leafy field', {'iou_scores': 0.31598111649766075}), ('a blueberry in the foreground or background of a green field', {'iou_scores': 0.315473548496185}), ('one round, blue sphere', {'iou_scores': 0.31041608965208684}), ('one blueberry in a field of green leaves', {'iou_scores': 0.2223174678010415}), ('blueberry in the background of a green field', {'iou_scores': 0.220645907892763}), ('blueberry among a patch of green leaves', {'iou_scores': 0.21827705386085053}), ('blueberry in the background of a leafy field', {'iou_scores': 0.2179215156775756}), ('a blueberry among a patch of green leaves', {'iou_scores': 0.21372603739561644}), ('a blue sphere  among a patch of green leaves', {'iou_scores': 0.21287128712871287}), ('a round blueberry among a patch of green leaves', {'iou_scores': 0.2120945409269476})]\n"
     ]
    }
   ],
   "source": [
    "prompt_result = prompt_optimizer(prompts_file, reference_txt, reference_image, \"best.txt\", box_threshold, DINO)\n",
    "\n",
    "top_2 = prompt_result[:2]\n",
    "top2 = [result[0] for result in prompt_result][0:2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying prompt: 'blue sphere'\n",
      "Confidence: 0.0, IoU: 0.05072426621759726 (Best IoU: 0.05072426621759726)\n",
      "Confidence: 0.1, IoU: 0.4112817961316002 (Best IoU: 0.4112817961316002)\n",
      "Confidence: 0.2, IoU: 0.927526649034223 (Best IoU: 0.927526649034223)\n",
      "Confidence: 0.3, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.4, IoU: 0.2884772074274197 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.5, IoU: 0.10518292682926829 (Best IoU: 0.9714591509097396)\n",
      "Best IoU at precision 1 is 0.9714591509097396 with confidence = 0.3\n",
      "Confidence: 0.2, IoU: 0.927526649034223 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.21, IoU: 0.927526649034223 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.22, IoU: 0.940243332723986 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.23, IoU: 0.940243332723986 (Best IoU: 0.9714591509097396)\n",
      "Best IoU at precision 2 is 0.9714591509097396 with confidence = 0.3\n",
      "Confidence: 0.29, IoU: 0.959717211925198 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.291, IoU: 0.959717211925198 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.292, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.293, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.294, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.295, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Best IoU at precision 3 is 0.9714591509097396 with confidence = 0.3\n",
      "Confidence: 0.299, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.2991, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.2992, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.2993, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.2994, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.2995, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.2996, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.2997, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Best IoU at precision 4 is 0.9714591509097396 with confidence = 0.3\n",
      "Confidence: 0.2999, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.29991, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.29992, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.29993, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.29994, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.29995, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.29996, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.29997, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.29998, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Confidence: 0.29999, IoU: 0.9714591509097396 (Best IoU: 0.9714591509097396)\n",
      "Best IoU at precision 5 is 0.9714591509097396 with confidence = 0.3\n",
      "So far: best prompt is 'blue sphere', conf is 0.3, resulting in 0.9714591509097396 IOU)\n",
      "Trying prompt: 'blueberries'\n",
      "Confidence: 0.0, IoU: 0.050738820592714784 (Best IoU: 0.050738820592714784)\n",
      "Confidence: 0.1, IoU: 0.13405422872079537 (Best IoU: 0.13405422872079537)\n",
      "Confidence: 0.2, IoU: 0.5050942963537287 (Best IoU: 0.5050942963537287)\n",
      "Confidence: 0.3, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.4, IoU: 0.7746642063253658 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.5, IoU: 0.04438041585137721 (Best IoU: 0.9682576954275712)\n",
      "Best IoU at precision 1 is 0.9682576954275712 with confidence = 0.3\n",
      "Confidence: 0.2, IoU: 0.5050942963537287 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.21, IoU: 0.5050942963537287 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.22, IoU: 0.5050942963537287 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.23, IoU: 0.5050942963537287 (Best IoU: 0.9682576954275712)\n",
      "Best IoU at precision 2 is 0.9682576954275712 with confidence = 0.3\n",
      "Confidence: 0.29, IoU: 0.9545043244039477 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.291, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.292, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.293, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.294, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.295, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Best IoU at precision 3 is 0.9682576954275712 with confidence = 0.3\n",
      "Confidence: 0.299, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.2991, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.2992, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.2993, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.2994, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.2995, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.2996, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.2997, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Best IoU at precision 4 is 0.9682576954275712 with confidence = 0.3\n",
      "Confidence: 0.2999, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.29991, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.29992, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.29993, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.29994, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.29995, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.29996, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.29997, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.29998, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Confidence: 0.29999, IoU: 0.9682576954275712 (Best IoU: 0.9682576954275712)\n",
      "Best IoU at precision 5 is 0.9682576954275712 with confidence = 0.3\n",
      "So far: best prompt is 'blue sphere', conf is 0.3, resulting in 0.9714591509097396 IOU)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Final Result: best prompt is 'blue sphere', conf is 0.3, resulting in 0.9714591509097396 IOU)\n",
      "final time: 30.39535427093506\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'prompt': 'blue sphere', 'conf': 0.3, 'iou': 0.9714591509097396}"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_optimizer(reference_image, reference_txt, DINO, top2, box_threshold)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_automatic_annotation():\n",
    "    message_box = QtWidgets.QMessageBox()\n",
    "\n",
    "    prompt_result = optimize_prompts(self.prompts_list_label.text(), self.labelled_folder_label.text()+\"\\\\labels\", self.labelled_folder_label.text()+\"\\\\images\", \"best.txt\", 0.8 )\n",
    "    top_10 = prompt_result[:5]\n",
    "    multi_optimize(self.labelled_folder_label.text()+\"\\\\labels\", self.labelled_folder_label.text()+\"\\\\images\", \"swint\", top10, )\n",
    "    # Then run using the optimized parameters\n",
    "\n",
    "\n",
    "    message_box.setStyleSheet(\"QLabel { color: black; font-size: 24px; } QMessageBox { background-color: white; }\")\n",
    "    message_box.setText(\"Annotations saved to the output folder.\")\n",
    "    message_box.exec_()\n",
    "\n",
    "    def prompt_selection(self):\n",
    "        if not hasattr(self, \"prompt_buttons_added\"):\n",
    "            list_prompts_btn = QtWidgets.QPushButton(\"List of Prompts\")\n",
    "            list_prompts_btn.setStyleSheet(\"background-color: #4f82ff; color: white; font-size: 24px;\")\n",
    "            list_prompts_btn.setFixedSize(400, 100)\n",
    "            list_prompts_btn.clicked.connect(self.handle_list_of_prompts)\n",
    "            self.right_layout.addWidget(list_prompts_btn, alignment=QtCore.Qt.AlignTop)\n",
    "\n",
    "            generate_prompts_btn = QtWidgets.QPushButton(\"Generate Prompts\")\n",
    "            generate_prompts_btn.setStyleSheet(\"background-color: #4f82ff; color: white; font-size: 24px;\")\n",
    "            generate_prompts_btn.setFixedSize(400, 100)\n",
    "            generate_prompts_btn.clicked.connect(self.handle_generate_prompts)\n",
    "            self.right_layout.addWidget(generate_prompts_btn, alignment=QtCore.Qt.AlignTop)\n",
    "\n",
    "            self.prompt_buttons_added = True\n",
    "\n",
    "    def handle_list_of_prompts(self):\n",
    "        message_box = QtWidgets.QMessageBox()\n",
    "        message_box.setStyleSheet(\"QLabel { color: black; font-size: 24px; } QMessageBox { background-color: white; }\")\n",
    "        options = QtWidgets.QFileDialog.Options()\n",
    "        options |= QtWidgets.QFileDialog.DontUseNativeDialog\n",
    "        dialog = QtWidgets.QFileDialog(self, \"Select Prompts List\", \"\", \"Image Files (*.txt *.csv)\", options=options)\n",
    "        dialog.setStyleSheet(\"QWidget { background-color: white; color: black; }\")\n",
    "        if dialog.exec_() == QtWidgets.QDialog.Accepted:\n",
    "            sample_image_path = dialog.selectedFiles()[0]\n",
    "            if sample_image_path:\n",
    "                prompt = \"a sample prompt\"  # Update this as needed\n",
    "                prompts = generate_prompts(sample_image_path, prompt)\n",
    "                if prompts:\n",
    "                    message_box = QtWidgets.QMessageBox()\n",
    "                    message_box.setStyleSheet(\"QLabel { color: black; font-size: 24px; } QMessageBox { background-color: white; }\")\n",
    "                    message_box.setText(\"Selected list of prompts.\")\n",
    "                    message_box.exec_()\n",
    "\n",
    "    def handle_generate_prompts(self):\n",
    "        options = QtWidgets.QFileDialog.Options()\n",
    "        options |= QtWidgets.QFileDialog.DontUseNativeDialog\n",
    "        dialog = QtWidgets.QFileDialog(self, \"Select Sample Image\", \"\", \"Image Files (*.png *.jpg *.jpeg)\", options=options)\n",
    "        dialog.setStyleSheet(\"QWidget { background-color: white; color: black; }\")\n",
    "        if dialog.exec_() == QtWidgets.QDialog.Accepted:\n",
    "            sample_image_path = dialog.selectedFiles()[0]\n",
    "            if sample_image_path:\n",
    "                prompt = \"a sample prompt\"  # Update this as needed\n",
    "                prompts = generate_prompts(sample_image_path, prompt)\n",
    "                if prompts:\n",
    "                    message_box = QtWidgets.QMessageBox()\n",
    "                    message_box.setStyleSheet(\"QLabel { color: black; font-size: 24px; } QMessageBox { background-color: white; }\")\n",
    "                    message_box.setText(\"\\n\".join(prompts))\n",
    "                    message_box.exec_()\n",
    "\n",
    "    def generate_prompts(self, image_path, prompt):\n",
    "        # This is a placeholder for the actual logic to generate prompts\n",
    "        return [\"Prompt 1\", \"Prompt 2\", \"Prompt 3\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
