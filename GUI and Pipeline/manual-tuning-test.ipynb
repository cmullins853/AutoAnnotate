{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from groundingdino.util.inference import load_model, load_image, predict\n",
    "import cv2\n",
    "import torch\n",
    "import csv\n",
    "import os\n",
    "from ultralytics import SAM\n",
    "from pathlib import Path\n",
    "import time as t\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def clean_labels(boxes, max_area):\n",
    "    clean_boxes = []\n",
    "    box_list = boxes.tolist()\n",
    "    for box in box_list:\n",
    "        # if width * height < 0.9, add box to list.\n",
    "        if (box[2] * box[3]) < max_area:\n",
    "            clean_boxes.append(box)\n",
    "    if len(clean_boxes) < 2:\n",
    "        return boxes\n",
    "    return torch.FloatTensor(clean_boxes)\n",
    "\n",
    "\n",
    "def run_dino(img_path, prompt, box_threshold, text_threshold, model_size, max_area=0.8, save_dir=\"DINO-labels\"):\n",
    "    # choose swinb or swint\n",
    "    if model_size == 'swint':\n",
    "        config_path = r\"GroundingDINO\\groundingdino\\config\\GroundingDINO_SwinT_OGC.py\"\n",
    "        checkpoint_path = r\"GroundingDINO\\weights\\groundingdino_swint_ogc.pth\"\n",
    "    else:\n",
    "        checkpoint_path = r\"GroundingDINO\\weights\\groundingdino_swinb_cogcoor.pth\"\n",
    "        config_path = r\"GroundingDINO\\groundingdino\\config\\GroundingDINO_SwinB_cfg.py\"\n",
    "\n",
    "    model = load_model(config_path, checkpoint_path)\n",
    "\n",
    "    image_source, image = load_image(img_path)\n",
    "\n",
    "    boxes, accuracy, obj_name = predict(model=model,\n",
    "                                        image=image,\n",
    "                                        caption=prompt,\n",
    "                                        box_threshold=box_threshold,\n",
    "                                        text_threshold=text_threshold)\n",
    "\n",
    "    # Convert boxes from YOLOv8 format to xyxy\n",
    "    img_height, img_width = cv2.imread(img_path).shape[:2]\n",
    "    clean_boxes = clean_labels(boxes, max_area)\n",
    "    absolute_boxes = [[(box[0] - (box[2] / 2)) * img_width,\n",
    "                       (box[1] - (box[3] / 2)) * img_height,\n",
    "                       (box[0] + (box[2] / 2)) * img_width,\n",
    "                       (box[1] + (box[3] / 2)) * img_height] for box in clean_boxes.tolist()]\n",
    "    # annotated_frame = annotate(image_source=image_source, boxes=clean_boxes, logits=accuracy, phrases=obj_name)\n",
    "    # sv.plot_image(annotated_frame, (16,16))\n",
    "    save_labels = True\n",
    "    if save_labels:\n",
    "        clean_boxes = clean_boxes.tolist()\n",
    "\n",
    "        for x in clean_boxes:\n",
    "            x.insert(0, 0)\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "\n",
    "        with open(f'{save_dir}/{os.path.splitext(os.path.basename(img_path))[0]}.txt', 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=' ')\n",
    "            writer.writerows(clean_boxes)\n",
    "\n",
    "    return absolute_boxes, accuracy\n",
    "\n",
    "\n",
    "def save_masks(sam_results, output_dir):\n",
    "    segments = sam_results[0].masks.xyn\n",
    "    with open(f\"{Path(output_dir) / Path(sam_results[0].path).stem}.txt\", \"w\") as f:\n",
    "        for i in range(len(segments)):\n",
    "            s = segments[i]\n",
    "            if len(s) == 0:\n",
    "                continue\n",
    "            segment = map(str, segments[i].reshape(-1).tolist())\n",
    "            f.write(f\"0 \" + \" \".join(segment) + \"\\n\")\n",
    "\n",
    "\n",
    "def run(img_dir, output_dir, prompt, conf, box_threshold=0.8):\n",
    "    sam_model = \"sam2_t.pt\"\n",
    "    dino_model = \"swint\"\n",
    "    start = t.time()\n",
    "\n",
    "    for fname in os.listdir(img_dir):\n",
    "        path = img_dir + \"\\\\\" + fname\n",
    "        boxes, _ = run_dino(path, prompt, conf, 0.1, dino_model, max_area=box_threshold)\n",
    "        model = SAM(sam_model)\n",
    "        sam_results = model(os.path.join(img_dir, fname), model=sam_model, bboxes=boxes, verbose=False)\n",
    "        save_masks(sam_results, output_dir)\n",
    "    print(f\"Completed in: {t.time() - start} seconds, masks saved in {output_dir}\")\n",
    "    return sam_results\n",
    "\n",
    "def run_image(img_dir, output_dir, prompt, conf, box_threshold):\n",
    "    sam_model = \"sam2_t.pt\"\n",
    "    dino_model = \"swint\"\n",
    "    start = t.time()\n",
    "    fname = os.path.basename(img_dir)\n",
    "    path = img_dir\n",
    "    boxes, _ = run_dino(img_dir, prompt, conf, 0.1, box_threshold)\n",
    "    model = SAM(sam_model)\n",
    "    sam_results = model(img_dir, model=sam_model, bboxes=boxes, verbose=False)\n",
    "    save_masks(sam_results, output_dir)\n",
    "\n",
    "    print(f\"Completed in: {t.time() - start} seconds, masks saved in {output_dir}\")\n",
    "    return sam_results\n",
    "\n",
    "\n",
    "\n",
    "def optimize_prompts(prompts_file, gt_path, img_dir, save_file, threshold):\n",
    "    inf_path = fr\"GroundingDINO\\DINO-labels\"\n",
    "\n",
    "    with open(prompts_file, 'r') as file:\n",
    "        result_dict = {}\n",
    "        for x in file:\n",
    "            result_dict[x.strip()] = {}\n",
    "\n",
    "    # result_dict = dict.fromkeys(prompts,{})\n",
    "    for prompt in result_dict.keys():\n",
    "        print(f'Trying prompt: \"{prompt}\"')\n",
    "        for fname in os.listdir(img_dir):\n",
    "            box_threshold = 0.3\n",
    "            text_threshold = 0.1\n",
    "            model_size = 'swint'\n",
    "            run_dino(os.path.join(img_dir, fname), prompt, box_threshold, text_threshold, model_size)\n",
    "\n",
    "        metrics = process_files(inf_path, gt_path, threshold=threshold)\n",
    "\n",
    "        result_dict[prompt]['iou_scores'] = np.mean(metrics['iou_scores'])\n",
    "\n",
    "    results = sorted(list(result_dict.items()), key=lambda a: a[1]['iou_scores'], reverse=True)\n",
    "    print(results)\n",
    "\n",
    "    with open(save_file, 'w') as output:\n",
    "        for prompt_stats in results:\n",
    "            output.write(str(prompt_stats) + '\\n')\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def optimize_confidence(prompt, model_size, gt_path, img_dir, threshold):\n",
    "    inf_path = r\"C:\\Users\\Mechanized Systems\\DataspellProjects\\WSU_joint_data\\Auto Annotate\\GroundingDINO\\DINO-labels\"\n",
    "    best_iou = 0\n",
    "    best_conf = 0\n",
    "    # number of decimal points in confidence\n",
    "    final_precision = 5\n",
    "    ubound = 0.9\n",
    "    lbound = 0.0\n",
    "    for precision in [x + 1 for x in range(final_precision)]:\n",
    "        esc = 0\n",
    "        for conf in [x / (10 ** precision) for x in\n",
    "                     range(int(lbound * (10 ** precision)), int(ubound * (10 ** precision)))]:\n",
    "            for fname in os.listdir(img_dir):\n",
    "                prompt = prompt\n",
    "                box_threshold = conf\n",
    "                text_threshold = 0.01\n",
    "                model_size = model_size\n",
    "                run_dino(os.path.join(img_dir, fname), prompt, box_threshold, text_threshold, model_size)\n",
    "            metrics = process_files(inf_path, gt_path, threshold)\n",
    "            iou = np.mean(metrics['iou_scores'])\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_conf = conf\n",
    "            else:\n",
    "                esc += 1\n",
    "                if esc > 2 * precision:\n",
    "                    break\n",
    "\n",
    "            print(f\"confidence: {conf}, IOU: {iou} (best: {best_iou})\")\n",
    "        print(f\"Best IOU at p{precision} is {best_iou} with confidence = {best_conf}\")\n",
    "        lbound = max(0, best_conf - (1 / (10 ** precision)))\n",
    "        ubound = min(0.9, best_conf + (1 / (10 ** precision)))\n",
    "\n",
    "        if (best_conf > (0.2 * (10 ** precision))) and precision >= 2:\n",
    "            print(f\"Final Result: Best IOU is {best_iou} with confidence = {best_conf}\")\n",
    "            return best_iou, best_conf\n",
    "\n",
    "    return best_iou, best_conf\n",
    "\n",
    "\n",
    "def multi_optimize(img_dir, gt_label_dir, model_size, prompts, threshold=0.4):\n",
    "    print(\"Be sure to change the category folders and model size in each function!\")\n",
    "    t.sleep(2)\n",
    "    start = t.time()\n",
    "    best_iou = 0\n",
    "    best_prompt = \"\"\n",
    "    best_conf = 0\n",
    "    for prompt in prompts:\n",
    "        print(f\"Trying prompt: '{prompt}'\")\n",
    "        iou, conf = optimize_confidence(prompt, model_size, gt_label_dir, img_dir, threshold)\n",
    "        if iou > best_iou:\n",
    "            best_iou = iou\n",
    "            best_conf = conf\n",
    "            best_prompt = prompt\n",
    "        print(f\"So far: best prompt is '{best_prompt}', conf is {best_conf}, resulting in {best_iou} IOU)\")\n",
    "    print(f\"\\n\\n\\n\\n\\nFinal Result: best prompt is '{best_prompt}', conf is {best_conf}, resulting in {best_iou} IOU)\")\n",
    "    print(f\"final time: {t.time() - start}\")\n",
    "    return {\"prompt\": best_prompt, \"conf\": best_conf, \"iou\": best_iou}\n",
    "\n",
    "\n",
    "def calculate_metrics(tp, fp, fn, tn):\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    mcc = ((tp * tn) - (fp * fn)) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) \\\n",
    "        if np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if tn + fp > 0 else 0\n",
    "    return precision, recall, f1, mcc, specificity\n",
    "\n",
    "\n",
    "def pixel_accuracy(predicted, ground_truth):\n",
    "    correct = np.sum(predicted == ground_truth)\n",
    "    total = predicted.shape[0] * predicted.shape[1]\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def read_and_draw_boxes(file_path, image_dim=(1280, 720)):\n",
    "    boxes = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            class_id, x, y, width, height = map(float, line.strip().split())\n",
    "            x1 = (x - (width / 2)) * image_dim[0]\n",
    "            x2 = (x + (width / 2)) * image_dim[0]\n",
    "            y1 = (y - (height / 2)) * image_dim[1]\n",
    "            y2 = (y + (height / 2)) * image_dim[1]\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "    image = Image.new('L', image_dim, 0)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box in boxes:\n",
    "        draw.rectangle(box, fill=255)\n",
    "        # draw.rectangle([1,1,20,20], fill=255)\n",
    "    image.save(\"test.jpg\")\n",
    "    return np.array(image, dtype=np.uint8)\n",
    "\n",
    "\n",
    "def calculate_pixel_metrics(mask1, mask2):\n",
    "    \"\"\"\n",
    "    Calculate IoU based on pixel values from two masks.\n",
    "    \"\"\"\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "def clean_labels_from_file(file_path, cleaning_threshold=0.6):\n",
    "    # Read the file and check if it has more than one line\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    if len(lines) > 1:\n",
    "        accepted_lines = []\n",
    "\n",
    "        # Process each line\n",
    "        for line in lines:\n",
    "            class_id, x, y, width, height = map(float, line.strip().split())\n",
    "            # if width * height < 0.9:\n",
    "            if (width * height) < cleaning_threshold:\n",
    "                accepted_lines.append(line)\n",
    "\n",
    "        # Overwrite the file with accepted lines\n",
    "        with open(file_path, 'w') as f:\n",
    "            if len(accepted_lines) > 0:\n",
    "                for line in accepted_lines:\n",
    "                    f.write(line)\n",
    "\n",
    "\n",
    "def process_files(predicted_mask_dir, ground_truth_mask_dir, threshold):\n",
    "    predicted_files = os.listdir(ground_truth_mask_dir)\n",
    "    metrics = {\n",
    "        'iou_scores': [],\n",
    "        'pixel_accuracies': [],\n",
    "        'precision_scores': [],\n",
    "        'recall_scores': [],\n",
    "        'f1_scores': [],\n",
    "        'mcc_scores': [],\n",
    "        'specificity_scores': []\n",
    "    }\n",
    "\n",
    "    for fname in predicted_files:\n",
    "        predicted_mask_path = os.path.join(predicted_mask_dir, fname)\n",
    "        ground_truth_mask_path = os.path.join(ground_truth_mask_dir, os.path.splitext(fname)[0] + '.txt')\n",
    "\n",
    "        if not os.path.exists(ground_truth_mask_path):\n",
    "            metrics['iou_scores'].append(0)\n",
    "            metrics['pixel_accuracies'].append(0)\n",
    "            metrics['precision_scores'].append(0)\n",
    "            metrics['recall_scores'].append(0)\n",
    "            metrics['f1_scores'].append(0)\n",
    "            metrics['mcc_scores'].append(0)\n",
    "            metrics['specificity_scores'].append(0)\n",
    "            continue\n",
    "\n",
    "        clean_labels_from_file(predicted_mask_path, threshold)\n",
    "        predicted_mask = read_and_draw_boxes(predicted_mask_path)\n",
    "        ground_truth_mask = read_and_draw_boxes(ground_truth_mask_path)\n",
    "\n",
    "        common_height, common_width = 1280, 720  # or any other desired size\n",
    "\n",
    "        predicted_mask = cv2.resize(predicted_mask, (common_width, common_height))\n",
    "\n",
    "        ground_truth_mask = cv2.resize(ground_truth_mask, (common_width, common_height))\n",
    "\n",
    "        _, predicted_mask_bin = cv2.threshold(predicted_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        _, ground_truth_mask_bin = cv2.threshold(ground_truth_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        predicted_mask_bin = predicted_mask_bin / 255\n",
    "        ground_truth_mask_bin = ground_truth_mask_bin / 255\n",
    "        tp = np.float64(np.sum(np.logical_and(predicted_mask_bin == 1, ground_truth_mask_bin == 1)))\n",
    "        tn = np.float64(np.sum(np.logical_and(predicted_mask_bin == 0, ground_truth_mask_bin == 0)))\n",
    "        fp = np.float64(np.sum(np.logical_and(predicted_mask_bin == 1, ground_truth_mask_bin == 0)))\n",
    "        fn = np.float64(np.sum(np.logical_and(predicted_mask_bin == 0, ground_truth_mask_bin == 1)))\n",
    "\n",
    "        intersection = np.logical_and(predicted_mask_bin, ground_truth_mask_bin)\n",
    "        union = np.logical_or(predicted_mask_bin, ground_truth_mask_bin)\n",
    "        metrics['iou_scores'].append(np.sum(intersection) / np.sum(union))\n",
    "        metrics['pixel_accuracies'].append(pixel_accuracy(predicted_mask_bin, ground_truth_mask_bin))\n",
    "        precision, recall, f1, mcc, specificity = calculate_metrics(tp, fp, fn, tn)\n",
    "        metrics['precision_scores'].append(precision)\n",
    "        metrics['recall_scores'].append(recall)\n",
    "        metrics['f1_scores'].append(f1)\n",
    "        metrics['mcc_scores'].append(mcc)\n",
    "        metrics['specificity_scores'].append(specificity)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def adjust_masks(sam_results):\n",
    "    result = sam_results[0]\n",
    "\n",
    "    masks = result.masks.data.cpu().numpy()     # masks, (N, H, W)\n",
    "    masks = np.moveaxis(masks, 0, -1) # masks, (H, W, N)\n",
    "    masks = np.moveaxis(masks, -1, 0) # masks, (N, H, W)\n",
    "\n",
    "    return masks\n",
    "\n",
    "def overlay(image, mask, color, alpha, resize=None):\n",
    "\n",
    "    color = color[::-1]\n",
    "    colored_mask = np.expand_dims(mask, 0).repeat(3, axis=0)\n",
    "    colored_mask = np.moveaxis(colored_mask, 0, -1)\n",
    "    masked = np.ma.MaskedArray(image, mask=colored_mask, fill_value=color)\n",
    "    image_overlay = masked.filled()\n",
    "\n",
    "    if resize is not None:\n",
    "        image = cv2.resize(image.transpose(1, 2, 0), resize)\n",
    "        image_overlay = cv2.resize(image_overlay.transpose(1, 2, 0), resize)\n",
    "\n",
    "    image_combined = cv2.addWeighted(image, 1 - alpha, image_overlay, alpha, 0)\n",
    "\n",
    "    return image_combined\n",
    "\n",
    "def overlay_with_borders(image, mask, color, thickness=2):\n",
    "    # Convert mask to uint8 type\n",
    "    mask_uint8 = (mask * 255).astype(np.uint8)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw contours on the image\n",
    "    cv2.drawContours(image, contours, -1, color, thickness)\n",
    "\n",
    "    return image\n",
    "\n",
    "def display_with_borders(image_path, prompt, confidence, max_area):\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    sam_results = run_image(image_path, \"\", prompt, confidence, box_threshold=max_area)\n",
    "    masks = adjust_masks(sam_results)\n",
    "\n",
    "    # Overlay borders of masks on the original image\n",
    "    image_with_borders = np.copy(img)\n",
    "    for mask_i in masks:\n",
    "        image_with_borders = overlay_with_borders(image_with_borders, mask_i, color=(255, 0, 255), thickness=2)\n",
    "\n",
    "    # Saving the image\n",
    "    cv2.imwrite('out.png', image_with_borders)\n",
    "    cv2.resize(image_with_borders, (640, 640))\n",
    "    cv2.imshow('image with borders', image_with_borders)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "def display(image_path, prompt, confidence, max_area):\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    sam_results = run_image(image_path, \"\", prompt, confidence, box_threshold=max_area)\n",
    "    masks = adjust_masks(sam_results)\n",
    "\n",
    "    # overlay masks on original image\n",
    "    image_with_masks = np.copy(img)\n",
    "    for mask_i in masks:\n",
    "        image_with_masks = overlay(image_with_masks, mask_i, color=(255, 0 ,255), alpha=0.2)\n",
    "\n",
    "    # Saving the image\n",
    "    cv2.imwrite('out.png', image_with_masks)\n",
    "    cv2.resize(image_with_masks, (640, 640))\n",
    "    cv2.imshow('image with masks', image_with_masks)\n",
    "\n",
    "    cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3610.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in: 4.866471529006958 seconds, masks saved in \n",
      "final text_encoder_type: bert-base-uncased\n",
      "Completed in: 3.466874837875366 seconds, masks saved in \n",
      "invalid command. Try again.\n",
      "final text_encoder_type: bert-base-uncased\n",
      "Completed in: 3.6775765419006348 seconds, masks saved in \n"
     ]
    }
   ],
   "source": [
    "image_dir = r\"C:\\Users\\Mechanized Systems\\Downloads\\cheese folder\"\n",
    "\n",
    "confidence = 0.2\n",
    "max_area = 0.9\n",
    "prompt = \"cheese\"\n",
    "command = \"\"\n",
    "for fname in os.listdir(image_dir):\n",
    "    display_with_borders(image_dir + \"\\\\\" + fname, prompt, confidence, max_area)\n",
    "    t.sleep(2)\n",
    "\n",
    "    cont = True\n",
    "    while cont:\n",
    "        command = input(\"type a command\")\n",
    "        match command:\n",
    "            case \"confup\":\n",
    "                confidence = min(1, confidence + 0.05)\n",
    "                display_with_borders(image_dir + \"\\\\\" + fname, prompt, confidence, max_area)\n",
    "            case \"confdown\":\n",
    "                confidence = max(0, confidence - 0.05)\n",
    "                display_with_borders(image_dir + \"\\\\\" + fname, prompt, confidence, max_area)\n",
    "            case \"boxup\":\n",
    "                max_area = min(1, max_area + 0.05)\n",
    "                display_with_borders(image_dir + \"\\\\\" + fname, prompt, confidence, max_area)\n",
    "            case \"boxdown\":\n",
    "                max_area = max(0, max_area - 0.05)\n",
    "                display_with_borders(image_dir + \"\\\\\" + fname, prompt, confidence, max_area)\n",
    "            case \"next\":\n",
    "                cont = False\n",
    "            case \"prompt\":\n",
    "                prompt = input(\"type the new prompt\")\n",
    "                display_with_borders(image_dir + \"\\\\\" + fname, prompt, confidence, max_area)\n",
    "            case _:\n",
    "                print(\"invalid command. Try again.\")\n",
    "print(\"done all images in folder.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
